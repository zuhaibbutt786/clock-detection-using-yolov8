{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zuhaibbutt786/clock-detection-using-yolov8/blob/main/clock2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcUZNKYY4Z0H",
        "outputId": "9ab6cec1-4a62-4aa6-a60f-35c655cb8520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.51-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2024.12.14)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.26.4)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.55.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.51-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, python-dotenv, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 python-dotenv-1.0.1 roboflow-1.1.51\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in wall-clocks-2 to yolov8:: 100%|██████████| 16118/16118 [00:00<00:00, 41750.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to wall-clocks-2 in yolov8:: 100%|██████████| 588/588 [00:00<00:00, 4075.05it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"APcOd7lQQJUjDLmWP0gL\")\n",
        "project = rf.workspace(\"giftprojects\").project(\"wall-clocks\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1T7aUMY8UnB",
        "outputId": "79aeb8d3-fec4-4f5a-8e37-0e288b159a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.70-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.70-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.70 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVya-qXi8TZS",
        "outputId": "46873bd7-e40d-4205-8511-61f61fe09bf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 68.4MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.70 🚀 Python-3.11.11 torch-2.5.1+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/wall-clocks-2/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 14.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/wall-clocks-2/train/labels... 252 images, 21 backgrounds, 0 corrupt: 100%|██████████| 252/252 [00:00<00:00, 355.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/wall-clocks-2/train/labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of Albumentations is available: 2.0.2 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/wall-clocks-2/valid/labels... 24 images, 5 backgrounds, 0 corrupt: 100%|██████████| 24/24 [00:00<00:00, 833.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/wall-clocks-2/valid/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 4, len(boxes) = 44. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50         0G      1.633      2.698      1.775        103        640:  75%|███████▌  | 12/16 [03:04<00:58, 14.56s/it]"
          ]
        }
      ],
      "source": [
        "# Step 3: Train YOLOv8 Model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pre-trained YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # You can use 'yolov8s', 'yolov8m', 'yolov8l', or 'yolov8x'\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=f\"{dataset.location}/data.yaml\", epochs=50, imgsz=640, batch=16)\n",
        "\n",
        "# Step 4: Evaluate the Model\n",
        "metrics = model.val()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkSK2iCS8dKh"
      },
      "outputs": [],
      "source": [
        "# Step 5: Run Inference on a Test Image\n",
        "results = model(f\"{dataset.location}/test/images/your_test_image.jpg\")  # Replace with your test image path\n",
        "results[0].show()  # Display the results\n",
        "results[0].save('/content/detected_image.jpg')  # Save the results\n",
        "\n",
        "# Step 6: Export the Model (Optional)\n",
        "model.export(format='onnx')  # Export to ONNX format\n",
        "\n",
        "# Step 7: Download the Trained Model\n",
        "from google.colab import files\n",
        "files.download('/content/runs/detect/train/weights/best.pt')  # Download the best model weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: test pytouch gpu code\n",
        "\n",
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"CUDA is not available\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Example tensor operations on GPU if CUDA is available\n",
        "if device.type == \"cuda\":\n",
        "    x = torch.randn(1000, 1000).to(device)\n",
        "    y = torch.randn(1000, 1000).to(device)\n",
        "    z = x + y\n",
        "    print(f\"Tensor operation on device: {z.device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGfkkmza6YTI",
        "outputId": "0f178a83-149c-462f-9346-c829dba829d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available\n",
            "Tensor operation on device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuo6Cm4m7A0F",
        "outputId": "78075518-55b5-4937-859a-4f747ca6f9f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.70-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.70-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.70 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"APcOd7lQQJUjDLmWP0gL\")\n",
        "project = rf.workspace(\"giftprojects\").project(\"wall-clock-2\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n85CSZzb7LnF",
        "outputId": "bf7106ff-60aa-443c-e514-88ae5adb1b71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.53-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2024.12.14)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.26.4)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.55.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.53-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, python-dotenv, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 python-dotenv-1.0.1 roboflow-1.1.53\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in wall-clock-2-1 to yolov8:: 100%|██████████| 14436/14436 [00:00<00:00, 28297.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to wall-clock-2-1 in yolov8:: 100%|██████████| 780/780 [00:00<00:00, 5010.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i have dataset of clock images with 2 class write a yolov8 code for fine tuning\n",
        "\n",
        "# Assuming you've already installed the necessary libraries and have the dataset downloaded as in the previous code.\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pre-trained YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # You can choose a different size model if needed\n",
        "\n",
        "# Define the path to your dataset's YAML file\n",
        "data_yaml_path = f\"/content/wall-clock-2-1/data.yaml\"\n",
        "\n",
        "# Train the model with specified hyperparameters\n",
        "results = model.train(data=data_yaml_path, epochs=100, imgsz=640, batch=16, patience=20) # Increased epochs and added patience\n",
        "\n",
        "# Evaluate the model\n",
        "metrics = model.val()\n",
        "metrics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3XeyhVE60j-",
        "outputId": "bee494ca-1373-4137-e60e-b75e0bba91ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.70 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/wall-clock-2-1/data.yaml, epochs=100, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/wall-clock-2-1/train/labels... 336 images, 36 backgrounds, 0 corrupt: 100%|██████████| 336/336 [00:00<00:00, 1840.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/wall-clock-2-1/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 156, len(boxes) = 1722. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.2 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/wall-clock-2-1/valid/labels... 32 images, 1 backgrounds, 0 corrupt: 100%|██████████| 32/32 [00:00<00:00, 1275.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/wall-clock-2-1/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      1/100      2.36G      1.557      2.778      1.664        170        640: 100%|██████████| 21/21 [00:11<00:00,  1.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206     0.0322      0.728      0.258      0.153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      2/100       2.3G      1.552      2.137       1.69        152        640: 100%|██████████| 21/21 [00:05<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.739      0.379      0.472      0.303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      3/100       2.3G      1.509      2.041      1.674        189        640: 100%|██████████| 21/21 [00:09<00:00,  2.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.572      0.388      0.454      0.291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      4/100       2.2G      1.583      2.056       1.75        119        640: 100%|██████████| 21/21 [00:05<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.31      0.155      0.127     0.0462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      5/100       2.2G      1.559       2.01      1.695        126        640: 100%|██████████| 21/21 [00:08<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.419      0.194      0.241      0.144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      6/100      2.22G      1.511        1.9      1.676        102        640: 100%|██████████| 21/21 [00:05<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.562      0.393      0.424      0.265\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      7/100      2.24G      1.497      1.923      1.688        136        640: 100%|██████████| 21/21 [00:08<00:00,  2.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.56      0.432      0.439      0.274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      8/100       2.2G      1.507      1.925        1.7        185        640: 100%|██████████| 21/21 [00:05<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.54      0.422      0.419      0.242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      9/100      2.21G      1.457      1.803      1.628        123        640: 100%|██████████| 21/21 [00:06<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.524       0.47      0.452      0.268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     10/100      2.32G      1.439      1.807      1.613        106        640: 100%|██████████| 21/21 [00:06<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.494      0.422      0.423       0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     11/100      2.18G      1.452      1.841      1.637        162        640: 100%|██████████| 21/21 [00:05<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.777      0.427       0.54       0.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     12/100      2.23G      1.425      1.831      1.622        137        640: 100%|██████████| 21/21 [00:07<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.755      0.404      0.501      0.317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "     13/100      2.21G      1.401      1.752      1.608        166        640: 100%|██████████| 21/21 [00:05<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.656      0.462      0.505      0.334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     14/100      2.24G      1.445      1.744      1.627        133        640: 100%|██████████| 21/21 [00:08<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.783      0.354      0.461      0.298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     15/100      2.32G      1.369      1.707      1.574        124        640: 100%|██████████| 21/21 [00:05<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.655      0.396      0.487      0.317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     16/100      2.23G      1.344        1.7      1.568        120        640: 100%|██████████| 21/21 [00:07<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.595      0.421      0.482       0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     17/100      2.21G        1.4      1.741      1.616        163        640: 100%|██████████| 21/21 [00:05<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.62      0.412      0.458      0.291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     18/100       2.2G      1.401      1.723      1.607        133        640: 100%|██████████| 21/21 [00:06<00:00,  3.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.554       0.26      0.281      0.164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     19/100      2.19G      1.355      1.684      1.562        148        640: 100%|██████████| 21/21 [00:06<00:00,  3.42it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.686      0.467      0.549      0.366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     20/100      2.21G      1.291      1.588      1.526        149        640: 100%|██████████| 21/21 [00:05<00:00,  3.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.777      0.523      0.611      0.416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     21/100      2.19G      1.249      1.512      1.477        174        640: 100%|██████████| 21/21 [00:07<00:00,  2.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.552      0.296       0.35      0.231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     22/100      2.31G      1.321      1.618      1.527        172        640: 100%|██████████| 21/21 [00:05<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.719      0.422       0.49      0.348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     23/100      2.18G      1.339      1.634      1.553        160        640: 100%|██████████| 21/21 [00:08<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.738       0.51      0.599      0.421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     24/100      2.17G      1.279      1.578      1.488        171        640: 100%|██████████| 21/21 [00:05<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.737       0.51      0.582      0.385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     25/100       2.3G      1.323      1.621      1.559        162        640: 100%|██████████| 21/21 [00:07<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.74      0.466       0.56      0.351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     26/100      2.16G      1.271      1.612      1.505         97        640: 100%|██████████| 21/21 [00:04<00:00,  4.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.805      0.481      0.577       0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     27/100      2.27G      1.207      1.462      1.451        132        640: 100%|██████████| 21/21 [00:06<00:00,  3.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.658      0.529      0.568      0.385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     28/100      2.22G      1.242      1.495      1.472        130        640: 100%|██████████| 21/21 [00:06<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.824      0.534      0.635      0.429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     29/100      2.22G      1.249      1.539       1.49        107        640: 100%|██████████| 21/21 [00:05<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.734      0.535        0.6      0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     30/100      2.21G      1.213      1.487      1.456        122        640: 100%|██████████| 21/21 [00:06<00:00,  3.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.796      0.417      0.515      0.343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     31/100      2.32G      1.267      1.498      1.482        116        640: 100%|██████████| 21/21 [00:05<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.717      0.505      0.578      0.387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     32/100      2.21G       1.27      1.589      1.511        126        640: 100%|██████████| 21/21 [00:07<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.71      0.511      0.593      0.415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     33/100      2.22G      1.208      1.479      1.451        156        640: 100%|██████████| 21/21 [00:05<00:00,  4.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.695      0.437      0.526      0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     34/100       2.2G      1.178      1.407      1.427        137        640: 100%|██████████| 21/21 [00:07<00:00,  2.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.734      0.553      0.619      0.442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     35/100      2.22G      1.196      1.472      1.445        111        640: 100%|██████████| 21/21 [00:05<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.718      0.539      0.615      0.416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     36/100      2.23G      1.195      1.368       1.43        133        640: 100%|██████████| 21/21 [00:06<00:00,  3.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.806      0.485      0.581        0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     37/100      2.21G      1.196        1.4      1.438        124        640: 100%|██████████| 21/21 [00:05<00:00,  3.54it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.678      0.437      0.502       0.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     38/100      2.16G      1.163      1.411      1.415        173        640: 100%|██████████| 21/21 [00:05<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.778      0.534       0.64      0.439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     39/100      2.28G      1.167      1.381      1.426        111        640: 100%|██████████| 21/21 [00:06<00:00,  3.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.779      0.524      0.605      0.427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     40/100      2.29G      1.089       1.31      1.363        134        640: 100%|██████████| 21/21 [00:05<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.82        0.5      0.603      0.402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     41/100      2.25G      1.155      1.309      1.395        131        640: 100%|██████████| 21/21 [00:07<00:00,  2.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.654      0.487      0.578      0.387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     42/100      2.29G       1.21      1.442      1.462        125        640: 100%|██████████| 21/21 [00:05<00:00,  4.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.659       0.32      0.373      0.236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     43/100      2.28G      1.144      1.366      1.419        182        640: 100%|██████████| 21/21 [00:08<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.828       0.51      0.635      0.442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     44/100       2.2G      1.064      1.246       1.34        144        640: 100%|██████████| 21/21 [00:05<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.84      0.544      0.622      0.433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     45/100      2.23G      1.108      1.286      1.371        157        640: 100%|██████████| 21/21 [00:06<00:00,  3.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.788      0.456       0.55      0.376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     46/100      2.18G      1.092      1.305      1.371        127        640: 100%|██████████| 21/21 [00:05<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.731      0.553      0.614      0.435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     47/100      2.31G      1.092      1.322      1.361        202        640: 100%|██████████| 21/21 [00:06<00:00,  3.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.708      0.442      0.546      0.358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     48/100      2.19G      1.101      1.278      1.379        139        640: 100%|██████████| 21/21 [00:06<00:00,  3.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.749      0.578      0.631      0.438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     49/100       2.2G      1.121      1.303      1.382        100        640: 100%|██████████| 21/21 [00:05<00:00,  4.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.701      0.545      0.606      0.417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     50/100      2.31G       1.04      1.184      1.328         95        640: 100%|██████████| 21/21 [00:07<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.788      0.524      0.637       0.43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     51/100      2.21G      1.024      1.184      1.312        138        640: 100%|██████████| 21/21 [00:05<00:00,  3.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.741      0.578      0.656      0.452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     52/100      2.22G      1.022      1.162       1.31        143        640: 100%|██████████| 21/21 [00:08<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.738      0.548      0.618      0.436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     53/100      2.19G      1.038      1.172      1.325        128        640: 100%|██████████| 21/21 [00:05<00:00,  4.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.854      0.541      0.658      0.479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     54/100      2.16G      1.054      1.167      1.339        121        640: 100%|██████████| 21/21 [00:07<00:00,  2.98it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.866      0.466      0.591      0.404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     55/100      2.15G      1.053      1.213      1.333        199        640: 100%|██████████| 21/21 [00:05<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.813      0.476      0.584      0.391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     56/100      2.19G     0.9868      1.129      1.291        173        640: 100%|██████████| 21/21 [00:05<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.782      0.523      0.614      0.418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     57/100       2.2G      1.034      1.169      1.317        176        640: 100%|██████████| 21/21 [00:07<00:00,  2.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.807      0.534      0.624       0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     58/100      2.18G      1.026      1.141      1.303        117        640: 100%|██████████| 21/21 [00:05<00:00,  4.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.691      0.402      0.447      0.278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     59/100      2.23G      1.022        1.1      1.285        153        640: 100%|██████████| 21/21 [00:08<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.816        0.5      0.577       0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     60/100      2.24G     0.9658      1.075      1.264        153        640: 100%|██████████| 21/21 [00:05<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.778       0.49      0.576      0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     61/100       2.2G      1.051      1.147      1.329        161        640: 100%|██████████| 21/21 [00:07<00:00,  2.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.787      0.515      0.595      0.405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     62/100      2.21G     0.9689      1.052      1.276        142        640: 100%|██████████| 21/21 [00:05<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.799      0.553      0.646      0.462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      2.22G      1.023      1.124      1.302        211        640: 100%|██████████| 21/21 [00:06<00:00,  3.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.844       0.49      0.599      0.433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100       2.3G     0.9831       1.07      1.289        151        640: 100%|██████████| 21/21 [00:06<00:00,  3.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.874       0.51      0.629      0.438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     65/100      2.22G     0.9662      1.054      1.273        174        640: 100%|██████████| 21/21 [00:05<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.854      0.558      0.655      0.471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     66/100      2.19G     0.9602      1.076      1.275        175        640: 100%|██████████| 21/21 [00:07<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.82      0.554      0.643      0.446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     67/100      2.28G     0.9377      1.026       1.24         97        640: 100%|██████████| 21/21 [00:05<00:00,  4.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.796      0.602      0.658      0.456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     68/100       2.2G     0.9857      1.073      1.291        111        640: 100%|██████████| 21/21 [00:08<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.819      0.534      0.617       0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     69/100       2.3G     0.9784      1.072      1.291        141        640: 100%|██████████| 21/21 [00:05<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.866      0.549      0.652      0.452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     70/100      2.29G     0.9628      1.025      1.256        127        640: 100%|██████████| 21/21 [00:07<00:00,  2.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.763      0.544      0.601      0.417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     71/100      2.21G     0.9497      1.029      1.258        199        640: 100%|██████████| 21/21 [00:05<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.756      0.563      0.609      0.424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     72/100      2.22G     0.9669      1.054      1.268        116        640: 100%|██████████| 21/21 [00:05<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206       0.85      0.515      0.607      0.431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     73/100      2.31G      0.916     0.9857       1.23        178        640: 100%|██████████| 21/21 [00:07<00:00,  2.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.775      0.568      0.633      0.442\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 53, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "73 epochs completed in 0.162 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.70 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.854      0.541      0.659      0.479\n",
            "             wallclock         31        206      0.854      0.541      0.659      0.479\n",
            "Speed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Ultralytics 8.3.70 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/wall-clock-2-1/valid/labels.cache... 32 images, 1 backgrounds, 0 corrupt: 100%|██████████| 32/32 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         32        206      0.854      0.541      0.657      0.479\n",
            "             wallclock         31        206      0.854      0.541      0.657      0.479\n",
            "Speed: 0.6ms preprocess, 11.9ms inference, 0.0ms loss, 4.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train22\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([1])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7c9f96b0c490>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,\n",
              "            0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.98507,     0.97143,\n",
              "            0.97143,     0.97143,     0.97143,     0.97143,     0.97143,     0.97143,     0.97143,     0.97143,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,\n",
              "            0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,\n",
              "            0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.96296,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,\n",
              "            0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.94253,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,\n",
              "            0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,\n",
              "            0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92157,     0.92035,     0.92035,     0.92035,     0.92035,\n",
              "            0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,\n",
              "            0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.92035,     0.91304,\n",
              "            0.91304,     0.91304,     0.91304,     0.91304,     0.90678,     0.90678,     0.90678,     0.90678,     0.90678,     0.90678,     0.90678,     0.90678,     0.90678,     0.89256,     0.89256,     0.89256,     0.89256,     0.89256,      0.8871,      0.8871,      0.8871,      0.8871,      0.8871,\n",
              "             0.8871,      0.8871,      0.8871,      0.8871,      0.8871,     0.88095,     0.88095,     0.88095,     0.88095,     0.88095,     0.85496,     0.85496,     0.85496,     0.85496,     0.85496,     0.84328,     0.84328,     0.84328,     0.84328,     0.83824,     0.83824,     0.83824,     0.83824,\n",
              "            0.83824,     0.83333,     0.83333,     0.83333,     0.83333,     0.83333,     0.80556,     0.80556,     0.80556,     0.80556,     0.80556,     0.80137,     0.80137,     0.80137,     0.80137,     0.80137,     0.79195,     0.79195,     0.79195,     0.79195,     0.79195,     0.77419,     0.77419,\n",
              "            0.77419,     0.77419,     0.77419,     0.77419,     0.77419,     0.77419,     0.77419,     0.71176,     0.71176,     0.71176,     0.71176,     0.71176,     0.69714,     0.69714,     0.69714,     0.69714,     0.69714,     0.67956,     0.67956,     0.67956,     0.67956,     0.67956,     0.65263,\n",
              "            0.65263,     0.65263,     0.65263,     0.65263,     0.62189,     0.62189,     0.62189,     0.62189,     0.62189,      0.6087,      0.6087,      0.6087,      0.6087,      0.6087,     0.56951,     0.56951,     0.56951,     0.56951,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,\n",
              "            0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.56466,     0.54321,     0.54321,     0.54321,     0.54321,     0.54321,     0.54065,     0.54065,     0.54065,\n",
              "            0.54065,     0.51737,     0.51737,     0.51737,     0.51737,     0.51737,     0.50752,     0.50752,     0.50752,     0.50752,     0.50752,     0.48239,     0.48239,     0.48239,     0.48239,     0.48239,     0.48239,     0.48239,     0.48239,     0.48239,     0.48239,     0.45098,     0.45098,\n",
              "            0.45098,     0.45098,     0.45098,     0.43711,     0.43711,     0.43711,     0.43711,     0.43711,     0.43077,     0.43077,     0.43077,     0.43077,     0.42598,     0.42598,     0.42598,     0.42598,     0.42598,      0.4152,      0.4152,      0.4152,      0.4152,      0.4152,     0.37632,\n",
              "            0.37632,     0.37632,     0.37632,     0.37632,     0.35821,     0.35821,     0.35821,     0.35821,     0.35821,     0.35784,     0.35784,     0.35784,     0.35784,     0.35784,     0.35784,     0.35784,     0.35784,     0.35784,     0.35784,     0.33716,     0.33716,     0.33716,     0.33716,\n",
              "            0.32244,     0.32244,     0.32244,     0.32244,     0.32244,     0.28876,     0.28876,     0.28876,     0.28876,     0.28876,     0.28736,     0.28736,     0.28736,     0.28736,     0.28736,     0.27706,     0.27706,     0.27706,     0.27706,     0.27706,     0.27437,     0.27437,     0.27437,\n",
              "            0.27437,     0.27437,     0.26516,     0.26516,     0.26516,     0.26516,     0.26325,     0.26325,     0.26325,     0.26325,     0.26325,     0.23994,     0.23994,     0.23994,     0.23994,     0.23994,     0.22082,     0.22082,     0.22082,     0.22082,     0.22082,     0.22082,     0.22082,\n",
              "            0.22082,     0.22082,     0.22082,      0.2044,      0.2044,      0.2044,      0.2044,      0.2044,     0.20332,     0.20332,     0.20332,     0.20332,     0.20332,         0.2,         0.2,         0.2,         0.2,     0.19031,     0.19031,     0.19031,     0.19031,     0.19031,     0.18451,\n",
              "            0.18451,     0.18451,     0.18451,     0.18451,     0.18151,     0.18151,     0.18151,     0.18151,     0.18151,     0.15938,     0.15938,     0.15938,     0.15938,     0.15938,     0.15911,     0.15911,     0.15911,     0.15911,     0.15911,     0.15091,     0.15091,     0.15091,     0.15091,\n",
              "            0.15091,     0.14069,     0.14069,     0.14069,     0.14069,     0.13907,     0.13907,     0.13907,     0.13907,     0.13907,     0.13706,     0.13706,     0.13706,     0.13706,     0.13706,      0.1346,      0.1346,      0.1346,      0.1346,      0.1346,     0.12761,     0.12761,     0.12761,\n",
              "            0.12761,     0.12761,     0.11398,     0.11398,     0.11398,     0.11398,     0.11398,      0.1119,      0.1119,      0.1119,      0.1119,     0.10841,     0.10841,     0.10841,     0.10841,     0.10841,    0.098094,    0.098094,    0.098094,    0.098094,    0.098094,     0.09181,     0.09181,\n",
              "            0.09181,     0.09181,     0.09181,    0.089939,    0.089939,    0.089939,    0.089939,    0.089939,    0.076956,    0.076956,    0.076956,    0.076956,    0.076956,    0.076956,    0.076956,    0.076956,    0.076956,    0.076956,    0.075314,    0.075314,    0.075314,    0.075314,    0.071823,\n",
              "           0.071823,    0.071823,    0.071823,    0.071823,    0.071823,    0.071823,    0.071823,    0.071823,    0.071823,    0.063785,    0.063785,    0.063785,    0.063785,    0.063785,    0.062099,    0.062099,    0.062099,    0.062099,    0.062099,    0.061977,    0.061977,    0.061977,    0.061977,\n",
              "           0.061977,    0.048742,    0.048742,    0.048742,    0.048742,    0.048742,    0.041695,    0.041695,    0.041695,    0.041695,     0.03468,     0.03468,     0.03468,     0.03468,     0.03468,     0.02999,     0.02999,     0.02999,     0.02999,     0.02999,    0.023787,    0.023497,    0.023207,\n",
              "           0.022917,    0.022626,    0.022336,    0.022046,    0.021756,    0.021466,    0.021176,    0.020886,    0.020596,    0.020306,    0.020016,    0.019726,    0.019436,    0.019145,    0.018855,    0.018565,    0.018275,    0.017985,    0.017695,    0.017405,    0.017115,    0.016825,    0.016535,\n",
              "           0.016245,    0.015955,    0.015664,    0.015374,    0.015084,    0.014794,    0.014504,    0.014214,    0.013924,    0.013634,    0.013344,    0.013054,    0.012764,    0.012474,    0.012183,    0.011893,    0.011603,    0.011313,    0.011023,    0.010733,    0.010443,    0.010153,   0.0098628,\n",
              "          0.0095727,   0.0092827,   0.0089926,   0.0087025,   0.0084124,   0.0081223,   0.0078322,   0.0075422,   0.0072521,    0.006962,   0.0066719,   0.0063818,   0.0060917,   0.0058017,   0.0055116,   0.0052215,   0.0049314,   0.0046413,   0.0043512,   0.0040612,   0.0037711,    0.003481,   0.0031909,\n",
              "          0.0029008,   0.0026107,   0.0023207,   0.0020306,   0.0017405,   0.0014504,   0.0011603,  0.00087025,  0.00058017,  0.00029008,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.046615,     0.04663,    0.068514,    0.092606,     0.11583,     0.13759,     0.15618,     0.17474,     0.19213,     0.20764,     0.22349,     0.23714,     0.24967,     0.26299,     0.27247,     0.28475,     0.29589,      0.3038,     0.31262,     0.32172,      0.3279,     0.33625,     0.34109,\n",
              "            0.35048,     0.35622,     0.36306,     0.36879,     0.37614,     0.38616,     0.38842,     0.39235,     0.39822,     0.40105,     0.40471,     0.41082,     0.41255,     0.41814,     0.42424,     0.42949,     0.43578,     0.44027,     0.44229,     0.44358,     0.44993,     0.45684,     0.45612,\n",
              "             0.4572,     0.46244,     0.46518,     0.46924,     0.47333,     0.47347,     0.47347,     0.47393,      0.4768,     0.48026,      0.4849,      0.4857,     0.48908,     0.49305,      0.4945,     0.49715,      0.5008,      0.5023,     0.50386,     0.50622,     0.50716,       0.508,     0.51173,\n",
              "            0.51313,     0.51522,     0.51807,     0.51576,     0.51785,     0.51958,     0.52138,     0.52495,     0.52342,     0.52646,     0.52698,     0.52455,     0.52621,     0.52712,     0.52944,     0.52817,     0.52882,     0.52959,     0.53211,     0.53404,     0.53556,     0.53655,      0.5381,\n",
              "             0.5371,     0.53974,      0.5409,     0.54199,     0.54311,     0.54541,     0.54615,     0.54663,     0.54717,     0.54783,     0.54876,     0.55225,     0.55343,     0.55427,     0.55627,      0.5575,     0.55862,     0.55577,     0.55683,     0.55726,     0.55769,     0.55999,     0.56192,\n",
              "            0.56616,     0.56956,     0.56987,     0.57183,     0.57433,     0.57522,     0.57432,     0.57856,     0.57958,     0.58011,     0.58065,     0.58224,      0.5828,     0.58391,     0.58719,     0.58583,      0.5873,      0.5851,     0.58548,     0.58586,     0.58684,     0.58767,     0.58797,\n",
              "            0.58827,     0.58856,     0.59028,      0.5913,     0.59191,     0.59246,      0.5931,     0.59385,     0.59507,     0.59582,     0.59632,     0.59684,     0.59737,     0.59479,     0.59201,     0.59193,     0.59021,     0.58852,     0.58683,     0.58739,     0.58816,     0.58869,     0.58923,\n",
              "            0.59101,     0.59105,     0.58907,     0.58955,     0.59003,      0.5906,      0.5912,     0.59355,      0.5948,     0.59541,     0.59593,     0.59634,     0.59675,     0.59719,     0.59877,     0.59923,     0.59968,     0.60016,     0.60072,     0.60128,      0.6023,      0.6036,     0.60495,\n",
              "             0.6063,     0.60782,     0.60893,     0.60945,     0.60998,     0.60906,     0.60731,     0.60706,     0.60743,      0.6078,     0.60816,     0.60921,     0.61028,     0.61116,     0.61203,     0.61281,     0.61317,     0.61353,     0.61388,     0.61424,     0.61292,     0.61153,     0.61147,\n",
              "            0.61372,     0.61413,     0.61441,     0.61469,     0.61496,     0.61524,     0.61565,     0.61621,     0.61677,     0.61726,     0.61774,     0.61821,     0.61882,      0.6196,     0.62007,     0.62021,     0.62035,     0.62049,     0.62064,     0.62078,     0.62092,     0.62106,      0.6212,\n",
              "            0.62134,     0.62148,     0.62167,      0.6219,     0.62214,     0.62237,      0.6226,     0.62283,     0.62306,     0.62387,     0.62488,     0.62611,     0.62387,     0.62466,     0.62567,     0.62621,     0.62658,     0.62694,      0.6273,     0.62927,     0.63102,     0.63191,     0.63272,\n",
              "            0.63343,     0.63492,     0.63387,      0.6343,     0.63473,     0.63516,     0.63551,     0.63576,     0.63601,     0.63625,     0.63649,     0.63674,     0.63698,     0.63718,     0.63736,     0.63753,     0.63771,     0.63788,     0.63805,     0.63823,      0.6384,     0.63858,     0.63876,\n",
              "            0.63943,     0.64009,     0.63697,     0.63746,     0.63795,     0.63844,     0.63966,     0.64048,     0.64093,     0.64138,     0.64183,     0.64221,     0.64258,     0.64295,     0.64332,     0.64346,     0.64268,     0.64191,     0.64114,     0.64036,     0.64017,     0.64048,      0.6408,\n",
              "            0.64112,     0.64143,     0.64186,      0.6432,      0.6436,      0.6438,     0.64401,     0.64421,     0.64442,     0.64462,     0.64482,     0.64502,     0.64524,     0.64547,      0.6457,     0.64593,     0.64616,     0.64639,     0.64663,     0.64686,     0.64704,     0.64722,     0.64739,\n",
              "            0.64756,     0.64774,     0.64791,     0.64809,     0.64826,     0.64843,     0.64861,     0.64958,     0.65057,     0.65107,     0.65158,     0.65208,     0.65281,     0.65359,       0.654,      0.6541,      0.6542,     0.65429,     0.65439,     0.65449,     0.65459,     0.65468,     0.65478,\n",
              "            0.65488,     0.65497,     0.65507,     0.65517,     0.65527,     0.65536,     0.65546,     0.65556,     0.65565,     0.65579,     0.65627,     0.65675,     0.65722,     0.65758,      0.6577,     0.65782,     0.65795,     0.65807,     0.65819,     0.65831,     0.65844,     0.65856,     0.65868,\n",
              "            0.65881,     0.65893,     0.65905,     0.65917,      0.6593,     0.65947,     0.65968,     0.65989,      0.6601,      0.6603,     0.66051,     0.66072,     0.66092,     0.66113,      0.6633,       0.664,      0.6647,     0.66439,     0.66387,     0.66335,     0.66283,     0.66231,     0.66178,\n",
              "            0.66126,     0.66045,     0.65951,     0.65858,     0.65764,     0.65743,     0.65749,     0.65756,     0.65762,     0.65769,     0.65775,     0.65782,     0.65788,     0.65795,     0.65801,     0.65808,     0.65814,     0.65821,     0.65827,     0.65834,      0.6584,     0.65847,     0.65853,\n",
              "             0.6586,     0.65866,     0.65873,     0.65879,     0.65885,     0.65892,     0.65898,     0.65905,     0.65911,     0.65918,     0.65928,     0.65944,     0.65961,     0.65977,     0.65993,      0.6601,     0.66026,     0.66042,     0.66058,     0.66075,     0.66091,     0.66109,     0.66173,\n",
              "            0.66237,     0.66316,     0.66468,     0.66368,     0.66268,     0.66168,     0.66111,     0.66137,     0.66163,      0.6619,     0.66216,     0.66243,     0.66269,     0.66323,     0.66464,     0.66442,     0.66403,     0.66365,     0.66326,     0.66287,     0.66248,     0.66209,     0.66171,\n",
              "            0.66132,     0.66145,     0.65926,      0.6592,     0.65938,     0.65956,     0.65974,     0.65992,     0.66009,     0.66027,     0.66045,     0.66063,     0.66081,       0.661,     0.66123,     0.66145,     0.66167,      0.6619,     0.66212,     0.66234,     0.66257,     0.66279,     0.66382,\n",
              "            0.66503,     0.66628,     0.66695,     0.66737,     0.66778,     0.66819,      0.6686,     0.66737,     0.66613,      0.6649,     0.66613,      0.6654,      0.6635,     0.66378,     0.66449,     0.66402,     0.66354,     0.66306,     0.66259,     0.66211,     0.66163,     0.66115,     0.66081,\n",
              "              0.661,      0.6612,      0.6614,      0.6616,      0.6618,       0.662,      0.6622,     0.66239,     0.66259,     0.66297,     0.66368,     0.66439,     0.66462,      0.6645,     0.66438,     0.66426,     0.66414,     0.66403,     0.66391,     0.66379,     0.66367,     0.66355,     0.66343,\n",
              "            0.66331,     0.66319,     0.66308,     0.66296,     0.66284,     0.66272,      0.6626,     0.66248,     0.66236,     0.66224,     0.66212,     0.66201,     0.66189,     0.66177,     0.66165,     0.66153,     0.66141,     0.66129,     0.66117,     0.66105,     0.66093,     0.66081,     0.66089,\n",
              "            0.66196,     0.66281,     0.66322,     0.66362,     0.66403,     0.66443,     0.66471,     0.66481,      0.6649,       0.665,     0.66509,     0.66519,     0.66529,     0.66538,     0.66548,     0.66557,     0.66567,     0.66576,     0.66586,     0.66596,     0.66605,     0.66615,     0.66624,\n",
              "            0.66634,     0.66643,     0.66653,     0.66662,     0.66858,     0.66822,     0.66775,     0.66729,     0.66682,     0.66635,     0.66588,     0.66541,     0.66494,     0.66471,     0.66487,     0.66503,     0.66519,     0.66535,     0.66551,     0.66566,     0.66582,     0.66598,     0.66614,\n",
              "             0.6663,     0.66645,     0.66661,     0.66243,     0.66138,     0.66034,     0.65929,     0.65857,     0.65871,     0.65884,     0.65897,      0.6591,     0.65923,     0.65936,      0.6595,     0.65963,     0.65976,     0.65989,     0.66002,     0.66015,     0.66028,     0.66041,     0.66054,\n",
              "            0.65648,     0.65655,     0.65661,     0.65668,     0.65674,     0.65681,     0.65687,     0.65694,       0.657,     0.65707,     0.65713,      0.6572,     0.65726,     0.65733,     0.65739,     0.65746,     0.65752,     0.65759,     0.65765,     0.65772,     0.65778,     0.65785,     0.65791,\n",
              "            0.65797,     0.65804,      0.6581,     0.65817,     0.65823,      0.6583,     0.65836,     0.65843,     0.65811,     0.65317,     0.65231,     0.65248,     0.65266,     0.65284,     0.65301,     0.65319,     0.65336,     0.65354,     0.65371,     0.65389,     0.65406,     0.65375,     0.65103,\n",
              "            0.65095,     0.65189,     0.65138,     0.65087,     0.65036,     0.64985,     0.64933,     0.64882,     0.64831,     0.64779,     0.64698,     0.64617,     0.64537,     0.64456,     0.64375,     0.64275,     0.64168,     0.64062,     0.63955,     0.63845,     0.63734,     0.63623,     0.63511,\n",
              "            0.63454,     0.63408,     0.63362,     0.63316,      0.6327,     0.63224,     0.63178,     0.63132,     0.63086,     0.63002,     0.62852,     0.62703,     0.62179,     0.62147,     0.62115,     0.62084,     0.62052,      0.6202,     0.61988,     0.61957,     0.61925,     0.61893,     0.61861,\n",
              "            0.61829,     0.61797,     0.61765,     0.61733,     0.61697,      0.6166,     0.61624,     0.61587,      0.6155,     0.61514,     0.61477,     0.61441,     0.61404,     0.61367,     0.61331,     0.61294,     0.61241,     0.61186,     0.61131,     0.61077,     0.61022,     0.60967,     0.60912,\n",
              "            0.60857,     0.60893,     0.60964,     0.61035,     0.60511,     0.60406,     0.60302,     0.60197,     0.60012,      0.5969,     0.59738,     0.59808,     0.59735,     0.59356,     0.59284,     0.59212,      0.5914,     0.59068,     0.58996,     0.58901,     0.58731,      0.5856,      0.5844,\n",
              "            0.58373,     0.58307,     0.58241,     0.58174,     0.58107,     0.58041,     0.57975,     0.57912,     0.57849,     0.57785,     0.57721,     0.57658,     0.57594,      0.5753,     0.57438,     0.57344,     0.57249,     0.57155,      0.5706,      0.5668,     0.56459,     0.56313,     0.56167,\n",
              "            0.56009,     0.55833,     0.55658,     0.55637,     0.55707,     0.55776,     0.55448,     0.55371,     0.55295,     0.55218,     0.55141,     0.55065,     0.54988,     0.54792,     0.54587,      0.5399,     0.54012,     0.54034,     0.54056,     0.54078,       0.541,     0.54122,     0.54143,\n",
              "            0.54165,      0.5434,     0.54235,      0.5413,     0.54025,     0.53919,     0.53787,     0.53593,     0.53399,     0.53273,     0.53181,     0.53088,     0.52996,     0.52904,     0.52809,     0.52682,     0.52555,     0.52427,       0.523,     0.52151,     0.52001,     0.51851,     0.49661,\n",
              "            0.49433,     0.49225,     0.49102,     0.49115,     0.49127,      0.4914,     0.49153,     0.49165,     0.49178,      0.4919,     0.49203,     0.49215,     0.49227,      0.4924,     0.49252,     0.49265,     0.49145,     0.48547,     0.48247,     0.48199,     0.48229,      0.4826,     0.48291,\n",
              "            0.48321,     0.48351,     0.48304,     0.48256,     0.48208,      0.4816,     0.48111,     0.48063,     0.48015,     0.47966,     0.47918,      0.4787,     0.47821,     0.47144,     0.46408,     0.46047,     0.45589,     0.45414,     0.45286,     0.45159,     0.45031,     0.44309,      0.4387,\n",
              "            0.43798,     0.43408,     0.42628,     0.42485,     0.42341,     0.42197,     0.42103,     0.42036,     0.41969,     0.41902,     0.41836,     0.41769,     0.41702,     0.41635,     0.41568,     0.41228,      0.4082,     0.40582,     0.40344,     0.40184,     0.40037,     0.39889,     0.39742,\n",
              "            0.39611,      0.3949,     0.39369,     0.39248,     0.39127,     0.37762,      0.3764,     0.37517,     0.37395,     0.37272,       0.371,     0.35886,     0.35705,     0.35549,     0.35392,     0.35236,     0.34527,      0.3441,     0.34292,     0.34175,     0.34057,     0.33939,     0.33122,\n",
              "            0.32935,     0.32749,     0.32562,     0.31571,     0.31089,     0.30828,     0.30566,     0.30374,     0.30234,     0.30094,     0.29954,     0.29814,      0.2966,     0.29494,     0.29328,     0.29162,      0.2898,     0.28763,     0.28546,     0.28322,     0.27878,     0.26833,     0.25684,\n",
              "            0.24329,     0.23894,     0.23491,     0.21596,     0.20809,     0.20285,     0.19857,     0.19486,     0.18918,     0.18175,     0.16847,     0.16422,     0.15975,     0.15434,     0.13956,     0.12555,     0.12029,     0.11682,     0.11412,      0.1114,     0.10517,    0.098092,    0.092615,\n",
              "           0.062866,    0.056233,     0.05231,    0.048371,     0.04627,    0.044774,    0.043277,    0.041777,    0.040274,     0.03877,    0.018924,    0.014735,     0.01053,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.023915,    0.023923,      0.0356,     0.04882,    0.061952,    0.074677,    0.085898,    0.097387,      0.1084,     0.11866,     0.12924,     0.13874,     0.14772,     0.15733,     0.16457,     0.17361,     0.18222,     0.18854,      0.1957,     0.20321,     0.20888,     0.21571,     0.22026,\n",
              "            0.22844,     0.23334,     0.23975,     0.24477,     0.25128,     0.26031,     0.26298,     0.26722,      0.2727,     0.27604,     0.28023,     0.28612,     0.28935,     0.29488,     0.30099,      0.3063,     0.31273,     0.31738,     0.31948,     0.32147,     0.32853,     0.33596,       0.336,\n",
              "            0.33744,     0.34318,      0.3462,     0.35072,     0.35532,     0.35651,     0.35796,     0.35978,      0.3631,     0.36713,     0.37258,     0.37482,     0.37899,     0.38378,     0.38554,     0.38877,     0.39325,      0.3951,     0.39704,     0.39997,     0.40116,      0.4022,      0.4069,\n",
              "            0.40867,     0.41133,     0.41509,     0.41378,     0.41647,     0.41871,     0.42106,     0.42586,     0.42561,     0.42964,     0.43057,     0.42903,     0.43127,     0.43249,     0.43562,     0.43561,     0.43682,     0.43788,     0.44133,       0.444,      0.4461,     0.44747,     0.45038,\n",
              "            0.45044,     0.45416,     0.45581,     0.45736,     0.45896,     0.46226,     0.46332,       0.464,     0.46479,     0.46574,     0.46708,     0.47216,     0.47389,     0.47512,     0.47808,     0.47989,     0.48205,     0.48247,     0.48406,     0.48471,     0.48537,     0.48886,     0.49181,\n",
              "            0.49835,     0.50363,     0.50703,     0.51014,     0.51414,     0.51669,      0.5172,     0.52411,     0.52578,     0.52667,     0.52755,     0.53019,     0.53111,     0.53296,     0.53845,     0.53905,     0.54206,      0.5418,     0.54245,      0.5431,      0.5448,     0.54623,     0.54674,\n",
              "            0.54726,     0.54777,     0.55075,     0.55252,     0.55359,     0.55456,     0.55568,       0.557,     0.55914,     0.56048,     0.56136,     0.56228,     0.56419,     0.56267,     0.56103,     0.56262,     0.56161,     0.56061,      0.5596,      0.5609,      0.5623,     0.56328,     0.56426,\n",
              "            0.56754,      0.5689,     0.56809,     0.56899,     0.56989,     0.57095,     0.57207,     0.57649,     0.57886,     0.58001,       0.581,     0.58178,     0.58256,      0.5834,     0.58643,      0.5873,     0.58816,     0.58909,     0.59018,     0.59126,     0.59322,     0.59575,     0.59839,\n",
              "            0.60105,     0.60405,     0.60622,     0.60727,     0.60831,     0.60807,     0.60708,     0.60732,     0.60806,      0.6088,     0.60954,     0.61165,      0.6138,     0.61558,     0.61736,     0.61895,     0.61968,     0.62041,     0.62114,     0.62187,     0.62115,     0.62039,     0.62131,\n",
              "            0.62597,     0.62682,      0.6274,     0.62798,     0.62856,     0.62914,        0.63,     0.63117,     0.63235,     0.63339,     0.63438,     0.63538,     0.63668,     0.63832,     0.63932,     0.63962,     0.63992,     0.64023,     0.64053,     0.64083,     0.64113,     0.64143,     0.64173,\n",
              "            0.64204,     0.64234,     0.64274,     0.64324,     0.64373,     0.64423,     0.64473,     0.64522,     0.64572,     0.64745,     0.64964,      0.6523,     0.65137,     0.65491,     0.65712,     0.65833,     0.65913,     0.65994,     0.66074,     0.66512,     0.66905,     0.67105,     0.67287,\n",
              "            0.67449,     0.67788,      0.6818,     0.68279,     0.68379,     0.68479,     0.68562,     0.68619,     0.68676,     0.68733,     0.68791,     0.68848,     0.68905,     0.68952,     0.68993,     0.69034,     0.69074,     0.69115,     0.69156,     0.69197,     0.69238,     0.69279,     0.69323,\n",
              "            0.69479,     0.69635,     0.69571,     0.69688,     0.69805,     0.69922,     0.70215,     0.70414,     0.70523,     0.70632,     0.70741,     0.70834,     0.70924,     0.71015,     0.71105,     0.71169,     0.71132,     0.71096,     0.71059,     0.71023,     0.71047,     0.71125,     0.71203,\n",
              "            0.71281,     0.71359,     0.71465,     0.71799,     0.71899,     0.71949,        0.72,     0.72051,     0.72102,     0.72153,     0.72204,     0.72255,     0.72308,     0.72367,     0.72425,     0.72483,     0.72541,       0.726,     0.72658,     0.72716,     0.72763,     0.72807,     0.72851,\n",
              "            0.72895,     0.72939,     0.72984,     0.73028,     0.73072,     0.73116,      0.7316,     0.73408,     0.73661,     0.73791,     0.73921,      0.7405,     0.74238,     0.74439,     0.74548,     0.74573,     0.74598,     0.74623,     0.74649,     0.74674,     0.74699,     0.74725,      0.7475,\n",
              "            0.74775,     0.74801,     0.74826,     0.74851,     0.74876,     0.74902,     0.74927,     0.74952,     0.74978,     0.75015,     0.75139,     0.75264,     0.75389,     0.75483,     0.75515,     0.75548,      0.7558,     0.75613,     0.75645,     0.75678,      0.7571,     0.75743,     0.75775,\n",
              "            0.75808,      0.7584,     0.75873,     0.75905,     0.75938,     0.75985,      0.7604,     0.76095,      0.7615,     0.76205,     0.76261,     0.76316,     0.76371,     0.76426,     0.77009,     0.77198,     0.77387,     0.77402,     0.77382,     0.77361,      0.7734,      0.7732,     0.77299,\n",
              "            0.77279,     0.77246,     0.77209,     0.77172,     0.77134,     0.77137,     0.77155,     0.77173,     0.77191,     0.77209,     0.77227,     0.77245,     0.77262,      0.7728,     0.77298,     0.77316,     0.77334,     0.77352,      0.7737,     0.77388,     0.77406,     0.77423,     0.77441,\n",
              "            0.77459,     0.77477,     0.77495,     0.77513,     0.77531,     0.77549,     0.77567,     0.77584,     0.77602,      0.7762,     0.77648,     0.77694,     0.77739,     0.77785,      0.7783,     0.77875,     0.77921,     0.77966,     0.78011,     0.78057,     0.78102,     0.78154,     0.78332,\n",
              "            0.78511,     0.78735,      0.7919,     0.79153,     0.79116,     0.79079,     0.79079,     0.79155,     0.79231,     0.79307,     0.79382,     0.79458,     0.79534,     0.79689,     0.80098,     0.80124,      0.8011,     0.80096,     0.80082,     0.80068,     0.80054,      0.8004,     0.80027,\n",
              "            0.80013,     0.80141,     0.80428,     0.80471,     0.80524,     0.80578,     0.80631,     0.80685,     0.80738,     0.80792,     0.80846,     0.80899,     0.80953,     0.81011,     0.81079,     0.81146,     0.81213,      0.8128,     0.81348,     0.81415,     0.81482,     0.81549,     0.81863,\n",
              "            0.82232,     0.82616,     0.82822,      0.8295,     0.83078,     0.83206,     0.83333,     0.83295,     0.83256,     0.83217,     0.83655,     0.83785,     0.83726,     0.84031,     0.84322,     0.84308,     0.84293,     0.84279,     0.84265,     0.84251,     0.84236,     0.84222,     0.84223,\n",
              "            0.84288,     0.84352,     0.84417,     0.84482,     0.84547,     0.84611,     0.84676,     0.84741,     0.84806,     0.84928,     0.85163,     0.85399,     0.85494,     0.85491,     0.85488,     0.85484,     0.85481,     0.85478,     0.85474,     0.85471,     0.85468,     0.85464,     0.85461,\n",
              "            0.85458,     0.85454,     0.85451,     0.85448,     0.85444,     0.85441,     0.85437,     0.85434,     0.85431,     0.85427,     0.85424,     0.85421,     0.85417,     0.85414,     0.85411,     0.85407,     0.85404,     0.85401,     0.85397,     0.85394,     0.85391,     0.85387,     0.85442,\n",
              "            0.85801,      0.8609,     0.86226,     0.86363,       0.865,     0.86637,     0.86732,     0.86765,     0.86797,      0.8683,     0.86863,     0.86896,     0.86928,     0.86961,     0.86994,     0.87026,     0.87059,     0.87092,     0.87125,     0.87157,      0.8719,     0.87223,     0.87256,\n",
              "            0.87288,     0.87321,     0.87354,     0.87387,     0.88063,     0.88084,     0.88073,     0.88062,     0.88051,      0.8804,     0.88029,     0.88018,     0.88007,     0.88021,     0.88077,     0.88133,     0.88188,     0.88244,       0.883,     0.88356,     0.88411,     0.88467,     0.88523,\n",
              "            0.88579,     0.88635,      0.8869,     0.88614,      0.8859,     0.88566,     0.88542,     0.88538,     0.88586,     0.88633,     0.88681,     0.88729,     0.88776,     0.88824,     0.88872,      0.8892,     0.88967,     0.89015,     0.89063,      0.8911,     0.89158,     0.89206,     0.89254,\n",
              "            0.89181,     0.89205,     0.89229,     0.89253,     0.89277,     0.89301,     0.89325,     0.89349,     0.89373,     0.89398,     0.89422,     0.89446,      0.8947,     0.89494,     0.89518,     0.89542,     0.89566,      0.8959,     0.89614,     0.89638,     0.89662,     0.89686,     0.89711,\n",
              "            0.89735,     0.89759,     0.89783,     0.89807,     0.89831,     0.89855,     0.89879,     0.89903,     0.90632,     0.90536,     0.90569,     0.90637,     0.90705,     0.90772,      0.9084,     0.90908,     0.90976,     0.91044,     0.91112,      0.9118,     0.91248,     0.91296,     0.91247,\n",
              "            0.91603,     0.92033,     0.92024,     0.92016,     0.92007,     0.91999,      0.9199,     0.91981,     0.91973,     0.91964,      0.9195,     0.91937,     0.91923,     0.91909,     0.91896,     0.91878,      0.9186,     0.91842,     0.91823,     0.91804,     0.91785,     0.91766,     0.91746,\n",
              "            0.91736,     0.91728,      0.9172,     0.91712,     0.91704,     0.91696,     0.91688,      0.9168,     0.91672,     0.91657,      0.9163,     0.91604,     0.91509,     0.91504,     0.91498,     0.91492,     0.91486,      0.9148,     0.91475,     0.91469,     0.91463,     0.91457,     0.91451,\n",
              "            0.91445,      0.9144,     0.91434,     0.91428,     0.91421,     0.91414,     0.91408,     0.91401,     0.91394,     0.91387,     0.91381,     0.91374,     0.91367,      0.9136,     0.91354,     0.91347,     0.91337,     0.91327,     0.91316,     0.91306,     0.91296,     0.91286,     0.91275,\n",
              "            0.91265,     0.91493,     0.91815,     0.92137,     0.92066,     0.92048,      0.9203,     0.92011,     0.91979,     0.91922,     0.92233,     0.92566,     0.92836,     0.92775,     0.92764,     0.92752,     0.92741,     0.92729,     0.92717,     0.92702,     0.92674,     0.92646,     0.92626,\n",
              "            0.92615,     0.92604,     0.92593,     0.92582,     0.92571,      0.9256,     0.92549,     0.92538,     0.92528,     0.92517,     0.92506,     0.92495,     0.92485,     0.92474,     0.92458,     0.92442,     0.92426,      0.9241,     0.92394,     0.92327,     0.92289,     0.92263,     0.92237,\n",
              "            0.92209,     0.92178,     0.92146,     0.92378,     0.92762,     0.93147,     0.94182,     0.94171,     0.94161,      0.9415,     0.94139,     0.94129,     0.94118,     0.94091,     0.94062,     0.94042,     0.94175,     0.94309,     0.94443,     0.94577,      0.9471,     0.94844,     0.94978,\n",
              "            0.95112,     0.96295,     0.96285,     0.96276,     0.96266,     0.96257,     0.96244,     0.96227,     0.96209,     0.96197,     0.96188,     0.96179,     0.96171,     0.96162,     0.96153,     0.96141,     0.96129,     0.96116,     0.96104,      0.9609,     0.96075,      0.9606,     0.95835,\n",
              "            0.95811,     0.95788,     0.95812,     0.95908,     0.96004,     0.96099,     0.96195,     0.96291,     0.96387,     0.96483,     0.96579,     0.96675,     0.96771,     0.96867,     0.96963,     0.97059,     0.97133,     0.97088,     0.97064,      0.9725,     0.97501,     0.97751,     0.98002,\n",
              "            0.98253,     0.98504,     0.98506,     0.98504,     0.98502,       0.985,     0.98498,     0.98496,     0.98494,     0.98492,      0.9849,     0.98488,     0.98486,     0.98458,     0.98426,      0.9841,      0.9839,     0.98382,     0.98376,      0.9837,     0.98365,     0.98331,     0.99283,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
              "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.91748,     0.91748,     0.90777,     0.89806,     0.88835,     0.87379,     0.85922,     0.84951,     0.84466,      0.8301,     0.82524,     0.81553,     0.80583,     0.80097,     0.79126,     0.79126,     0.78641,     0.78155,      0.7767,     0.77184,     0.76214,     0.76214,     0.75557,\n",
              "            0.75243,     0.75243,     0.74757,     0.74757,     0.74757,     0.74757,     0.74272,     0.73786,     0.73786,     0.73301,     0.72816,     0.72816,     0.71845,     0.71845,     0.71845,     0.71845,     0.71845,     0.71845,     0.71845,     0.71527,     0.71359,     0.71359,     0.70991,\n",
              "            0.70874,     0.70874,     0.70874,     0.70874,     0.70874,     0.70463,     0.69903,     0.69417,     0.69417,     0.69417,     0.69417,     0.68975,     0.68932,     0.68932,     0.68932,     0.68932,     0.68932,     0.68932,     0.68932,     0.68932,     0.68932,     0.68932,     0.68932,\n",
              "            0.68932,     0.68932,     0.68899,     0.68447,     0.68447,     0.68447,     0.68447,     0.68413,     0.67961,     0.67961,     0.67905,      0.6748,     0.67476,     0.67476,     0.67476,     0.67067,      0.6699,      0.6699,      0.6699,      0.6699,      0.6699,      0.6699,     0.66827,\n",
              "            0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66505,     0.66413,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,     0.65534,\n",
              "            0.65534,     0.65534,     0.65049,     0.65049,     0.65049,     0.64871,     0.64563,     0.64563,     0.64563,     0.64563,     0.64563,     0.64563,     0.64563,     0.64563,     0.64563,     0.64149,     0.64078,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,\n",
              "            0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63592,     0.63471,     0.63081,     0.62662,     0.62445,     0.62189,     0.61936,     0.61684,      0.6165,      0.6165,      0.6165,      0.6165,\n",
              "             0.6165,     0.61499,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61165,\n",
              "            0.61165,     0.61165,     0.61165,     0.61165,     0.61165,     0.61006,     0.60753,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6068,      0.6049,     0.60293,     0.60194,\n",
              "            0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,\n",
              "            0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.60194,     0.59861,     0.59709,     0.59709,     0.59709,     0.59709,     0.59709,     0.59709,     0.59709,     0.59709,     0.59709,     0.59709,\n",
              "            0.59709,     0.59709,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,     0.59223,\n",
              "            0.59223,     0.59223,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58738,     0.58717,     0.58613,     0.58509,     0.58405,     0.58301,     0.58252,     0.58252,     0.58252,\n",
              "            0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,\n",
              "            0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,\n",
              "            0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,\n",
              "            0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58252,     0.58196,     0.58128,     0.58059,     0.57991,     0.57923,     0.57855,\n",
              "            0.57787,     0.57681,     0.57559,     0.57437,     0.57315,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,\n",
              "            0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,     0.57282,\n",
              "            0.57282,     0.57282,     0.57267,     0.57139,      0.5701,     0.56882,     0.56796,     0.56796,     0.56796,     0.56796,     0.56796,     0.56796,     0.56796,     0.56796,     0.56796,     0.56751,     0.56702,     0.56652,     0.56603,     0.56553,     0.56504,     0.56454,     0.56405,\n",
              "            0.56355,     0.56311,     0.55855,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,\n",
              "            0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55825,     0.55671,     0.55516,     0.55362,      0.5534,     0.55182,     0.54947,     0.54854,     0.54828,     0.54769,      0.5471,     0.54652,     0.54593,     0.54534,     0.54475,     0.54416,     0.54369,\n",
              "            0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,     0.54369,      0.5436,     0.54346,     0.54331,     0.54317,     0.54302,     0.54288,     0.54273,     0.54259,     0.54244,      0.5423,     0.54215,\n",
              "            0.54201,     0.54186,     0.54172,     0.54157,     0.54143,     0.54128,     0.54114,     0.54099,     0.54085,      0.5407,     0.54055,     0.54041,     0.54026,     0.54012,     0.53997,     0.53983,     0.53968,     0.53954,     0.53939,     0.53925,      0.5391,     0.53896,     0.53883,\n",
              "            0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53883,\n",
              "            0.53883,     0.53883,     0.53883,     0.53883,     0.53883,     0.53829,     0.53772,     0.53716,     0.53659,     0.53603,     0.53546,      0.5349,     0.53433,     0.53398,     0.53398,     0.53398,     0.53398,     0.53398,     0.53398,     0.53398,     0.53398,     0.53398,     0.53398,\n",
              "            0.53398,     0.53398,     0.53398,      0.5289,     0.52766,     0.52641,     0.52517,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,     0.52427,\n",
              "            0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,\n",
              "            0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51942,     0.51662,     0.51086,     0.50971,     0.50971,     0.50971,     0.50971,     0.50971,     0.50971,     0.50971,     0.50971,     0.50971,     0.50971,     0.50971,     0.50918,     0.50604,\n",
              "            0.50485,     0.50469,      0.5041,     0.50351,     0.50293,     0.50234,     0.50175,     0.50117,     0.50058,     0.49999,     0.49907,     0.49815,     0.49723,     0.49631,     0.49539,     0.49426,     0.49305,     0.49184,     0.49064,      0.4894,     0.48815,      0.4869,     0.48565,\n",
              "            0.48501,      0.4845,     0.48399,     0.48347,     0.48296,     0.48245,     0.48193,     0.48142,      0.4809,     0.47996,     0.47831,     0.47665,     0.47087,     0.47052,     0.47017,     0.46982,     0.46947,     0.46913,     0.46878,     0.46843,     0.46808,     0.46773,     0.46738,\n",
              "            0.46703,     0.46669,     0.46634,     0.46598,     0.46559,     0.46519,     0.46479,     0.46439,     0.46399,     0.46359,      0.4632,      0.4628,      0.4624,       0.462,      0.4616,      0.4612,     0.46063,     0.46004,     0.45944,     0.45885,     0.45826,     0.45767,     0.45707,\n",
              "            0.45648,     0.45631,     0.45631,     0.45631,     0.45065,     0.44954,     0.44842,      0.4473,     0.44534,     0.44194,     0.44175,     0.44175,     0.44034,     0.43637,     0.43562,     0.43487,     0.43412,     0.43337,     0.43262,     0.43163,     0.42986,      0.4281,     0.42685,\n",
              "            0.42617,     0.42549,      0.4248,     0.42412,     0.42343,     0.42275,     0.42208,     0.42143,     0.42078,     0.42013,     0.41948,     0.41883,     0.41818,     0.41753,     0.41659,     0.41563,     0.41467,     0.41371,     0.41275,     0.40891,     0.40669,     0.40523,     0.40377,\n",
              "            0.40219,     0.40044,      0.3987,     0.39806,     0.39806,     0.39806,     0.39289,     0.39214,     0.39139,     0.39065,      0.3899,     0.38915,      0.3884,     0.38649,      0.3845,     0.37864,     0.37864,     0.37864,     0.37864,     0.37864,     0.37864,     0.37864,     0.37864,\n",
              "            0.37864,      0.3785,     0.37749,     0.37649,     0.37549,     0.37448,     0.37322,     0.37139,     0.36956,     0.36836,     0.36749,     0.36662,     0.36576,     0.36489,       0.364,     0.36281,     0.36163,     0.36044,     0.35925,     0.35787,     0.35648,     0.35509,     0.33513,\n",
              "             0.3331,     0.33124,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,      0.3301,     0.32894,     0.32366,     0.32102,     0.32039,     0.32039,     0.32039,     0.32039,\n",
              "            0.32039,     0.32039,     0.31997,     0.31955,     0.31913,     0.31871,     0.31829,     0.31787,     0.31745,     0.31703,     0.31661,     0.31619,     0.31577,     0.30991,     0.30362,     0.30055,     0.29667,      0.2952,     0.29413,     0.29306,     0.29199,     0.28598,     0.28155,\n",
              "            0.28039,      0.2772,     0.27088,     0.26972,     0.26856,      0.2674,     0.26664,     0.26611,     0.26558,     0.26504,     0.26451,     0.26397,     0.26344,      0.2629,     0.26237,     0.25967,     0.25644,     0.25456,     0.25269,     0.25144,     0.25029,     0.24914,     0.24799,\n",
              "            0.24697,     0.24603,     0.24509,     0.24415,     0.24322,     0.23276,     0.23183,      0.2309,     0.22997,     0.22904,     0.22775,     0.21866,     0.21732,     0.21616,     0.21501,     0.21385,     0.20866,      0.2078,     0.20695,     0.20609,     0.20523,     0.20438,     0.19848,\n",
              "            0.19714,     0.19581,     0.19447,     0.18744,     0.18406,     0.18223,      0.1804,     0.17906,     0.17809,     0.17712,     0.17615,     0.17519,     0.17412,     0.17298,     0.17184,      0.1707,     0.16946,     0.16797,     0.16649,     0.16497,     0.16197,     0.15496,     0.14734,\n",
              "            0.13849,     0.13568,     0.13308,     0.12105,     0.11612,     0.11287,     0.11023,     0.10794,     0.10447,    0.099962,    0.091984,    0.089454,    0.086807,    0.083626,    0.075016,     0.06698,    0.063995,    0.062036,    0.060512,    0.058988,    0.055503,    0.051575,    0.048556,\n",
              "           0.032453,     0.02893,    0.026858,    0.024785,    0.023683,      0.0229,    0.022117,    0.021334,    0.020551,    0.019768,   0.0095521,   0.0074224,   0.0052927,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
              "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: 0.4966101139590825\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([    0.47875,     0.47875])\n",
              "names: {0: 'person', 1: 'wallclock'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.8544082624302263, 'metrics/recall(B)': 0.541280712617975, 'metrics/mAP50(B)': 0.6573685591203263, 'metrics/mAP50-95(B)': 0.478748064496722, 'fitness': 0.4966101139590825}\n",
              "save_dir: PosixPath('runs/detect/train22')\n",
              "speed: {'preprocess': 0.561639666557312, 'inference': 11.927597224712372, 'loss': 0.0007227063179016113, 'postprocess': 4.413776099681854}\n",
              "task: 'detect'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: now write a test code to test a image\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load a trained YOLOv8 model\n",
        "# Replace 'path/to/your/best.pt' with the actual path to your trained model file\n",
        "model = YOLO('/content/runs/detect/train2/weights/best.pt')\n",
        "\n",
        "# Load the image you want to test\n",
        "# Replace 'path/to/your/test/image.jpg' with the actual path to your test image\n",
        "img = cv2.imread('/content/wall.jpg')\n",
        "\n",
        "# Perform inference\n",
        "results = model(img)\n",
        "\n",
        "# Display the results (optional)\n",
        "# cv2_imshow(results[0].plot()) # works in colab\n",
        "\n",
        "# Alternatively, you can save the image with bounding boxes\n",
        "results[0].save('output_images2.jpg')\n",
        "\n",
        "# Or access the bounding boxes directly\n",
        "boxes = results[0].boxes\n",
        "for box in boxes:\n",
        "    print(box)\n",
        "\n",
        "# Print class labels and confidence scores\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        class_id = box.cls[0].item()\n",
        "        confidence = box.conf[0].item()\n",
        "        print(f\"Class ID: {class_id}, Confidence: {confidence}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e9_lftI-4YJ",
        "outputId": "c4ebe3c2-aa10-4a80-bc7a-91a898f49fa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 480x640 7 wallclocks, 6.9ms\n",
            "Speed: 2.1ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([1.], device='cuda:0')\n",
            "conf: tensor([0.7929], device='cuda:0')\n",
            "data: tensor([[13.2290,  0.1397, 73.5449, 54.0146,  0.7929,  1.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (280, 390)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[43.3869, 27.0772, 60.3160, 53.8749]], device='cuda:0')\n",
            "xywhn: tensor([[0.1112, 0.0967, 0.1547, 0.1924]], device='cuda:0')\n",
            "xyxy: tensor([[13.2290,  0.1397, 73.5449, 54.0146]], device='cuda:0')\n",
            "xyxyn: tensor([[0.0339, 0.0005, 0.1886, 0.1929]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([1.], device='cuda:0')\n",
            "conf: tensor([0.6701], device='cuda:0')\n",
            "data: tensor([[241.2268,   0.0000, 300.4178,  41.8889,   0.6701,   1.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (280, 390)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[270.8223,  20.9445,  59.1910,  41.8889]], device='cuda:0')\n",
            "xywhn: tensor([[0.6944, 0.0748, 0.1518, 0.1496]], device='cuda:0')\n",
            "xyxy: tensor([[241.2268,   0.0000, 300.4178,  41.8889]], device='cuda:0')\n",
            "xyxyn: tensor([[0.6185, 0.0000, 0.7703, 0.1496]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([1.], device='cuda:0')\n",
            "conf: tensor([0.6067], device='cuda:0')\n",
            "data: tensor([[314.6839,  94.6692, 388.2354, 165.5919,   0.6067,   1.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (280, 390)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[351.4597, 130.1306,  73.5515,  70.9226]], device='cuda:0')\n",
            "xywhn: tensor([[0.9012, 0.4648, 0.1886, 0.2533]], device='cuda:0')\n",
            "xyxy: tensor([[314.6839,  94.6692, 388.2354, 165.5919]], device='cuda:0')\n",
            "xyxyn: tensor([[0.8069, 0.3381, 0.9955, 0.5914]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([1.], device='cuda:0')\n",
            "conf: tensor([0.4766], device='cuda:0')\n",
            "data: tensor([[ 99.4425,  83.5253, 148.6550, 136.6651,   0.4766,   1.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (280, 390)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[124.0487, 110.0952,  49.2125,  53.1398]], device='cuda:0')\n",
            "xywhn: tensor([[0.3181, 0.3932, 0.1262, 0.1898]], device='cuda:0')\n",
            "xyxy: tensor([[ 99.4425,  83.5253, 148.6550, 136.6651]], device='cuda:0')\n",
            "xyxyn: tensor([[0.2550, 0.2983, 0.3812, 0.4881]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([1.], device='cuda:0')\n",
            "conf: tensor([0.4736], device='cuda:0')\n",
            "data: tensor([[1.6281e+02, 1.8411e-01, 2.2720e+02, 3.6806e+01, 4.7364e-01, 1.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (280, 390)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[195.0036,  18.4950,  64.3871,  36.6217]], device='cuda:0')\n",
            "xywhn: tensor([[0.5000, 0.0661, 0.1651, 0.1308]], device='cuda:0')\n",
            "xyxy: tensor([[1.6281e+02, 1.8411e-01, 2.2720e+02, 3.6806e+01]], device='cuda:0')\n",
            "xyxyn: tensor([[0.4175, 0.0007, 0.5826, 0.1314]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([1.], device='cuda:0')\n",
            "conf: tensor([0.4042], device='cuda:0')\n",
            "data: tensor([[294.8761,   0.0000, 388.8991,  43.9152,   0.4042,   1.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (280, 390)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[341.8876,  21.9576,  94.0231,  43.9152]], device='cuda:0')\n",
            "xywhn: tensor([[0.8766, 0.0784, 0.2411, 0.1568]], device='cuda:0')\n",
            "xyxy: tensor([[294.8761,   0.0000, 388.8991,  43.9152]], device='cuda:0')\n",
            "xyxyn: tensor([[0.7561, 0.0000, 0.9972, 0.1568]], device='cuda:0')\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([1.], device='cuda:0')\n",
            "conf: tensor([0.2894], device='cuda:0')\n",
            "data: tensor([[137.8242, 140.5740, 203.2212, 202.4111,   0.2894,   1.0000]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (280, 390)\n",
            "shape: torch.Size([1, 6])\n",
            "xywh: tensor([[170.5227, 171.4925,  65.3970,  61.8370]], device='cuda:0')\n",
            "xywhn: tensor([[0.4372, 0.6125, 0.1677, 0.2208]], device='cuda:0')\n",
            "xyxy: tensor([[137.8242, 140.5740, 203.2212, 202.4111]], device='cuda:0')\n",
            "xyxyn: tensor([[0.3534, 0.5021, 0.5211, 0.7229]], device='cuda:0')\n",
            "Class ID: 1.0, Confidence: 0.7929251194000244\n",
            "Class ID: 1.0, Confidence: 0.6701254844665527\n",
            "Class ID: 1.0, Confidence: 0.6066555380821228\n",
            "Class ID: 1.0, Confidence: 0.47664517164230347\n",
            "Class ID: 1.0, Confidence: 0.4736405611038208\n",
            "Class ID: 1.0, Confidence: 0.4042295217514038\n",
            "Class ID: 1.0, Confidence: 0.28942424058914185\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPe3GNrJWSlNVl/HE4fr6SG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}